{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose: To build out the skeleton Pseudo Code for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For now__: Moving my notes from my one one one with Elizabeth and will build out more in the next few days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input .csv from experimental team to describe data\n",
    "2. CSV pulls the proper images from NDP (or wherever best storage location is determined to be)\n",
    "2a. There needs to be some integration with NDP to break the image into chunks with the appropriate zoom and then provide the original slice with locations of test and training images printed out.\n",
    "2b. I think to do this we are going to have to register the image to some kind of atlas... or somethign to determine regions so that the code can grab pictures\n",
    "3. Images need to be split\n",
    "3a. Regionally\n",
    "3b. Test Groups\n",
    "3c. Into Small enough sizes for most efficient processing by package\n",
    "3d. Magifications\n",
    "4. Threshold and segment\n",
    "4a. Ifthresholds (for general object identification) [July]\n",
    "4b. + Skeletonization (for specific highly branched morphometric analysis) [Robin]\n",
    "5. Split data into testing and training groups\n",
    "6. Shape factor analysis on both models (before ML model)\n",
    "7. Feed 4(1) and 4(2) separately to modified VAMPIRE package to build models\n",
    "8. Store created models\n",
    "9. Test models with testing data sets\n",
    "10. Data output\n",
    "11. Comprehensive CSV for optional additional analysis\n",
    "12. Data Visualization\n",
    "13. Save all data into some storage location (Google Drive?)\n",
    "\n",
    "\n",
    "Other Notes: \n",
    "1. Modified VAMPIRE package: Worth forking the Wirtz lab repository now and building on by ourselves possibly – adding that fork to our repository - COMPLETE\n",
    "2. Want a repository that works through Binder? Preferably so the Neonatalogy lab can do this straight through a web interface\n",
    "3. Along with outputs want to output the variables used for all of the steps on days that experiments were run with an easy print out maybe for lab notebook storage? (A way to integrate the electronic lab notebook I want to get more fine tuned for our lab with a standard lab notebook - and provide some under the hood knowledge for Neonatology)\n",
    "\n",
    "4. Add in an optimization step for what size of image is sufficient for cropping down the whole scan images \n",
    "5. Including an analysis before creating that analysis that selects the best # of shape modes and #coordinate points – maybe we could reach out the Denis Wirtz lab about this or build in our own integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Goal:\n",
    "\n",
    "1. Get a bunch of images from a slice of the ferret brain\n",
    "2. Put them in a folder\n",
    "3. Perform thresholding within the Jupyter Notebook\n",
    "3. Integrate vampire into the Jupyter Notebook\n",
    "4. Run those images and get an output within the notebook or specific folder (which should will need a results output)\n",
    "5. Save all of this information to some results folder\n",
    "6. See if it works in binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Goals:\n",
    "1. Build out ifthresholds more for immunohistochemistry stains\n",
    "2. Build in NDP regional registration and automatic image breakdown\n",
    "3. Integrate Google Drive\n",
    "4. New visualizations based on what came from paper\n",
    "5. Statistics possibly with Rthon\n",
    "6. Speed up any slow processes with Cython\n",
    "7. Integrate ifThresholds to pick and perform the best thresholding (or integrate a step to say whether this needs to be done or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Import necessary packages*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If import shows ERROR:\n",
    "\n",
    "\"Could not find Java JRE compatible with x86_64 architecture\" then close out of jupyter lab and exit that terminal window. Start a new window and before accessing Jupyter Lab fix the Java home\n",
    "\n",
    "http://www.sajeconsultants.com/how-to-set-java_home-on-mac-os-x/?utm_source=rss&utm_medium=rss&utm_campaign=how-to-set-java_home-on-mac-os-x\n",
    "\n",
    "' export JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk-14.0.1.jdk/Contents/Home'\n",
    "\n",
    "' echo $JAVA_HOME'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import vampireanalysis\n",
    "from vampireanalysis.vampire import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: User Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = '/Users/hhelmbre/Desktop/fiberf_data'\n",
    "image_file_type = '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Threshold and Segment Images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3a: Import and threshold images from 'data_folder'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir(data_folder)\n",
    "image_list = np.asarray(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing anything that isn't an image from the image list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for images in image_list:\n",
    "    if image_file_type in str(images):\n",
    "        k+=1\n",
    "    else:\n",
    "        image_list = np.delete(image_list, (k), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*back to what will be the main code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*need to go in and add code to create a reasonable cut off for the min_size remove small objects*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Go in and add code that does a better job at separating overlapping cells (maybe this is just in thresholding*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder for the new tresholded images\n",
    "os.mkdir(str(data_folder + '/' + 'threshold_applied_images'))\n",
    "\n",
    "#initializing a pandas dataframe\n",
    "overall_region_meas = pd.DataFrame(columns = ['Filename', 'ImageID', 'ObjectID', 'X', 'Y', 'Area', 'Perimeter', 'Major Axis', 'Minor Axis', 'Circularity', 'Aspect Ratio'])\n",
    "\n",
    "#initializing a count\n",
    "k=1\n",
    "\n",
    "#Looping through all images in list (this task should be put to multiple CPUs in future if a large data set)\n",
    "for images in image_list:\n",
    "    \n",
    "    \n",
    "    #initializing a pandas data frame for measurement data\n",
    "    region_meas = pd.DataFrame()\n",
    "    \n",
    "    #Going through each of the images to get their binarized images and measurement info\n",
    "    name = str(data_folder + '/' + images)\n",
    "    im = io.imread(name)\n",
    "    im = im[:,:,2]\n",
    "    threshold = filters.threshold_otsu(im)\n",
    "    binary = morphology.closing(im < threshold, morphology.square(5))\n",
    "    label_image = measure.label(binary, return_num=False, connectivity=2)\n",
    "    binary2 = morphology.remove_small_objects(label_image, min_size=400, connectivity=2, in_place=True)\n",
    "    invert_binary2 = np.invert(binary2)\n",
    "    \n",
    "    # Saving the thresheld images to their own folder with modified names\n",
    "    im_to_save = Image.fromarray(np.uint8(binary2), mode='L')\n",
    "    new_name = str(data_folder + '/' + 'threshold_applied_images' + '/' + images)\n",
    "    new_name = new_name.replace('.jpg','_threshold.jpg')\n",
    "    im_to_save.save(new_name)\n",
    "    \n",
    "    \n",
    "    #Saving the region properties as a csv\n",
    "    props = measure.regionprops_table(binary2, properties= ('centroid', 'area', 'perimeter', 'major_axis_length', 'minor_axis_length'))\n",
    "    props_meas = pd.DataFrame(props)\n",
    "    region_meas['X'] = props_meas['centroid-0']\n",
    "    region_meas['Y'] = props_meas['centroid-1']\n",
    "    region_meas['Area'] = props_meas['area']\n",
    "    region_meas['Perimeter'] = props_meas['perimeter']\n",
    "    region_meas['Major Axis'] = props_meas['major_axis_length']\n",
    "    region_meas['Minor Axis'] = props_meas['minor_axis_length']\n",
    "    region_meas['Circularity'] = (region_meas['Area']*4*np.pi)/(region_meas['Perimeter']**2)\n",
    "    region_meas['Aspect Ratio'] = (region_meas['Major Axis']/region_meas['Minor Axis'])\n",
    "    region_meas.insert(0, 'Filename', images)\n",
    "    region_meas.insert(1, 'ImageID', k)\n",
    "    region_meas.insert(2, 'ObjectID', np.arange(len(region_meas)))\n",
    "\n",
    "    overall_region_meas = overall_region_meas.append(region_meas)\n",
    "    k+=1\n",
    "\n",
    "path = '/Users/hhelmbre/Desktop/fiberf_data/threshold_applied_images/'\n",
    "overall_region_meas.to_csv(path+'c1_registry.csv', index=False)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Vampire Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual create entries\n",
    "#manual create a progress bar\n",
    "#input the entries, buidModel? and progress_bar into def Model of vampire.py (hope that works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "from tkinter.ttk import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {\n",
    "    'Number of shape modes': 5,\n",
    "    'Number of coordinates': 50,\n",
    "    'Status': 'welcome to vampire analysis',\n",
    "    'Model output folder': '/Users/hhelmbre/Desktop/fiberf_data/model',\n",
    "    'Image sets to build': '/Users/hhelmbre/Desktop/fiberf_data/model/images-to-apply-model.csv',\n",
    "    'Model to apply': '/Users/hhelmbre/Desktop/fiberf_data/model/images-to-apply-model.csv',\n",
    "    'Model name': 'vampire_practice'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "progress_bar = None\n",
    "\n",
    "buildModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'delete'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-7519d84f77aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cellpro/lib/python3.8/site-packages/vampireanalysis/vampire.py\u001b[0m in \u001b[0;36mModel\u001b[0;34m(entries, buildModel, progress_bar)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuildModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mentries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Status'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'modeling initiated...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# input definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'delete'"
     ]
    }
   ],
   "source": [
    "Model(entries, buildModel, progress_bar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5: Train and Test Split Images*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 6: Build model using VAMPIRE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 7: Apply model using VAMPIRE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 8: New visualization of VAMPIRE data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This should probably be built into VAMPIRE and not just into this notebook - think about this for the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
