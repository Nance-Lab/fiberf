{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose: To build out the skeleton Pseudo Code for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For now__: Moving my notes from my one one one with Elizabeth and will build out more in the next few days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input .csv from experimental team to describe data\n",
    "2. CSV pulls the proper images from NDP (or wherever best storage location is determined to be)\n",
    "2a. There needs to be some integration with NDP to break the image into chunks with the appropriate zoom and then provide the original slice with locations of test and training images printed out.\n",
    "2b. I think to do this we are going to have to register the image to some kind of atlas... or somethign to determine regions so that the code can grab pictures\n",
    "3. Images need to be split\n",
    "3a. Regionally\n",
    "3b. Test Groups\n",
    "3c. Into Small enough sizes for most efficient processing by package\n",
    "3d. Magifications\n",
    "4. Threshold and segment\n",
    "4a. Ifthresholds (for general object identification) [July]\n",
    "4b. + Skeletonization (for specific highly branched morphometric analysis) [Robin]\n",
    "5. Split data into testing and training groups\n",
    "6. Shape factor analysis on both models (before ML model)\n",
    "7. Feed 4(1) and 4(2) separately to modified VAMPIRE package to build models\n",
    "8. Store created models\n",
    "9. Test models with testing data sets\n",
    "10. Data output\n",
    "11. Comprehensive CSV for optional additional analysis\n",
    "12. Data Visualization\n",
    "13. Save all data into some storage location (Google Drive?)\n",
    "\n",
    "\n",
    "Other Notes: \n",
    "1. Modified VAMPIRE package: Worth forking the Wirtz lab repository now and building on by ourselves possibly – adding that fork to our repository - COMPLETE\n",
    "2. Want a repository that works through Binder? Preferably so the Neonatalogy lab can do this straight through a web interface\n",
    "3. Along with outputs want to output the variables used for all of the steps on days that experiments were run with an easy print out maybe for lab notebook storage? (A way to integrate the electronic lab notebook I want to get more fine tuned for our lab with a standard lab notebook - and provide some under the hood knowledge for Neonatology)\n",
    "\n",
    "4. Add in an optimization step for what size of image is sufficient for cropping down the whole scan images \n",
    "5. Including an analysis before creating that analysis that selects the best # of shape modes and #coordinate points – maybe we could reach out the Denis Wirtz lab about this or build in our own integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Goal:\n",
    "\n",
    "1. Get a bunch of images from a slice of the ferret brain\n",
    "2. Put them in a folder\n",
    "3. Perform thresholding within the Jupyter Notebook\n",
    "3. Integrate vampire into the Jupyter Notebook\n",
    "4. Run those images and get an output within the notebook or specific folder (which should will need a results output)\n",
    "5. Save all of this information to some results folder\n",
    "6. See if it works in binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Goals:\n",
    "1. Build out ifthresholds more for immunohistochemistry stains\n",
    "2. Build in NDP regional registration and automatic image breakdown\n",
    "3. Integrate Google Drive\n",
    "4. New visualizations based on what came from paper\n",
    "5. Statistics possibly with Rthon\n",
    "6. Speed up any slow processes with Cython\n",
    "7. Integrate ifThresholds to pick and perform the best thresholding (or integrate a step to say whether this needs to be done or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Import necessary packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: User Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data folder to the stain you are running morphology on (right now only works one stain at a time)\n",
    "#rerun for each individual stain\n",
    "\n",
    "#Folder breakdown: stain>animal>region>actual images\n",
    "data_folder = '/Users/hhelmbre/Desktop/6-17-2020-fiberfimages/iba1'\n",
    "\n",
    "#Image type of your images (they should all be the same type)\n",
    "image_file_type = '.jpg'\n",
    "\n",
    "#Enter the name of your stain as a string\n",
    "stain = 'Iba1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Google Drive Integration*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to this website: https://developers.google.com/drive/api/v3/quickstart/python?authuser=1\n",
    "2. Make sure the appropriate google account is open in the top right corner\n",
    "3. Click \"Enable the Drive API\" (blue button)\n",
    "4. Select 'Desktop App' from the drop down list\n",
    "5. Select Create\n",
    "6. Download the credentials\n",
    "7. Rename them client_secrets.json\n",
    "\n",
    "\n",
    "NOTE: client_secrets.json and credentials.json are files in the .gitignore for this respository. For online safety, do not change this or push either of these to Git to keep your google accounts secure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This runs the google integration - it will open another web browser. When allowed leave the authentication page open. \n",
    "#Sometimes there is an error when this page is closed.\n",
    "\n",
    "import pydrive\n",
    "from pydrive.auth import GoogleAuth as gauth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "\n",
    "#  Creates local webserver and auto handles authentication.\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "\n",
    "#  Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Threshold and segment everything and then split test and train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir(data_folder)\n",
    "folder_list = np.asarray(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for macs to get rid of an aesthetic file called '.DS_Store'\n",
    "k=0\n",
    "mac_annoyance= 'DS_Store'\n",
    "for folders in folder_list:\n",
    "    if mac_annoyance in str(folders):\n",
    "        folder_list = np.delete(folder_list, (k), axis=0)\n",
    "    else:\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder breadown should be (1) stains, (2) animals, (3) regions\n",
    "#this code gets a list of the individual paths for each region folder with images\n",
    "threshold_paths = []\n",
    "for animals in folder_list:\n",
    "    region_list = os.listdir(str(data_folder + '/' + animals))\n",
    "    region_list = np.asarray(region_list)\n",
    "    \n",
    "    k=0\n",
    "    for regions in region_list:\n",
    "        if mac_annoyance in str(regions):\n",
    "            region_list = np.delete(region_list, (k), axis=0)\n",
    "        else:\n",
    "            k+=1\n",
    "    \n",
    "    for regions in region_list:\n",
    "        path = str(data_folder + '/' + animals + '/' + regions)\n",
    "        threshold_paths.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Threshold and Segment Images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3a: Import and threshold images from 'data_folder' from downloaded NDP images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*need to go in and add code to create a reasonable cut off for the min_size remove small objects*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Go in and add code that does a better job at separating overlapping cells (maybe this is just in thresholding*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for paths in threshold_paths:\n",
    "\n",
    "    #Creating a folder for the new tresholded images\n",
    "    os.mkdir(str(paths + '/' + 'threshold_applied_images'))\n",
    "\n",
    "    #initializing a pandas dataframe\n",
    "    overall_region_meas = pd.DataFrame(columns = ['Filename', 'ImageID', 'ObjectID', 'X', 'Y', 'Area', 'Perimeter', 'Major Axis', 'Minor Axis', 'Circularity', 'Aspect Ratio'])\n",
    "\n",
    "    #initializing a count\n",
    "    \n",
    "    image_list = os.listdir(str(paths))\n",
    "    image_list = np.asarray(image_list)\n",
    "    \n",
    "    k=0\n",
    "    for images in image_list:\n",
    "        if image_file_type in str(images):\n",
    "            k+=1\n",
    "        else:\n",
    "            image_list = np.delete(image_list, (k), axis=0)\n",
    "    \n",
    "    \n",
    "    #Initializing an imag count\n",
    "    k=1\n",
    "    \n",
    "    #Looping through all images in list (this task should be put to multiple CPUs in future if a large data set)\n",
    "    for images in image_list:\n",
    "\n",
    "        #initializing a pandas data frame for measurement data\n",
    "        region_meas = pd.DataFrame()\n",
    "\n",
    "        #Going through each of the images to get their binarized images and measurement info\n",
    "        name = str(paths + '/' + images)\n",
    "        im = io.imread(name)\n",
    "        im = im[:,:,2]\n",
    "        threshold = filters.threshold_otsu(im)\n",
    "        binary = morphology.closing(im < threshold, morphology.square(5))\n",
    "        label_image = measure.label(binary, return_num=False, connectivity=2)\n",
    "        binary2 = morphology.remove_small_objects(label_image, min_size=400, connectivity=2, in_place=True)\n",
    "        invert_binary2 = np.invert(binary2)\n",
    "\n",
    "        # Saving the thresheld images to their own folder with modified names\n",
    "        im_to_save = Image.fromarray(np.uint8(binary2), mode='L')\n",
    "        new_name = str(paths + '/' + 'threshold_applied_images' + '/' + images)\n",
    "        new_name = new_name.replace('.jpg','_threshold.jpg')\n",
    "        im_to_save.save(new_name)\n",
    "\n",
    "\n",
    "        #Saving the region properties as a csv\n",
    "        props = measure.regionprops_table(binary2, properties= ('centroid', 'area', 'perimeter', 'major_axis_length', 'minor_axis_length'))\n",
    "        props_meas = pd.DataFrame(props)\n",
    "        region_meas['X'] = props_meas['centroid-0']\n",
    "        region_meas['Y'] = props_meas['centroid-1']\n",
    "        region_meas['Area'] = props_meas['area']\n",
    "        region_meas['Perimeter'] = props_meas['perimeter']\n",
    "        region_meas['Major Axis'] = props_meas['major_axis_length']\n",
    "        region_meas['Minor Axis'] = props_meas['minor_axis_length']\n",
    "        region_meas['Circularity'] = (region_meas['Area']*4*np.pi)/(region_meas['Perimeter']**2)\n",
    "        region_meas['Aspect Ratio'] = (region_meas['Major Axis']/region_meas['Minor Axis'])\n",
    "        region_meas.insert(0, 'Filename', images)\n",
    "        region_meas.insert(1, 'ImageID', k)\n",
    "        region_meas.insert(2, 'ObjectID', np.arange(len(region_meas)))\n",
    "\n",
    "        overall_region_meas = overall_region_meas.append(region_meas)\n",
    "        k+=1\n",
    "\n",
    "    path = str(paths + '/' + 'threshold_applied_images/')\n",
    "    overall_region_meas.to_csv(path + 'c1_registry.csv', index=False)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Test and Train Split before Thresholding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through all the threshold paths + the threshold folder and assign 8 of them for training and 2 of them for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths = []\n",
    "for animals in folder_list:\n",
    "    region_list = os.listdir(str(data_folder + '/' + animals))\n",
    "    region_list = np.asarray(region_list)\n",
    "    \n",
    "    k=0\n",
    "    for regions in region_list:\n",
    "        if mac_annoyance in str(regions):\n",
    "            region_list = np.delete(region_list, (k), axis=0)\n",
    "        else:\n",
    "            k+=1\n",
    "    \n",
    "    for regions in region_list:\n",
    "        path = str(data_folder + '/' + animals + '/' + regions + '/' + 'threshold_applied_images/')\n",
    "        test_paths.append(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(str(data_folder + '/' + 'train'))\n",
    "\n",
    "name_count = 0\n",
    "\n",
    "for paths in test_paths:\n",
    "    \n",
    "    image_list = os.listdir(str(paths))\n",
    "    image_list = np.asarray(image_list)\n",
    "    \n",
    "    k=0\n",
    "    for images in image_list:\n",
    "        if image_file_type in str(images):\n",
    "            k+=1\n",
    "        else:\n",
    "            image_list = np.delete(image_list, (k), axis=0)\n",
    "\n",
    "    X_train, X_test= train_test_split(image_list, test_size=0.20, random_state=1)\n",
    "\n",
    "    for names in image_list:\n",
    "        if names in X_train[:]:\n",
    "            shutil.move(str(paths + '/' + names), str(data_folder + '/' + 'train'))\n",
    "            \n",
    "            \n",
    "            train_name = str(data_folder + '/' + 'train/' + names)\n",
    "            string_count = str(name_count)\n",
    "            replace_name = str('xy' + string_count + stain + 'ch1' + '.jpg')\n",
    "            os.rename(str(data_folder + '/' + 'train/' + names), str(data_folder + '/' + 'train/' + replace_name))\n",
    "            name_count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Vampire Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following will pull up the GUI as a popup - I want to be able to input values into the GUI straight from here not have to point and click*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We are going to work with what we have an have a print out here of what to input in the VAMPIRE GUI - it is still faster than it used to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Build and then apply model with the vampire GUI (will work on making it not GUI later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Create the CSVs for Building and applying the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a model repository to store the output information\n",
    "#create a csv for building the model\n",
    "#create a csv for applying the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the directory in your data folder to put all information related to the model\n",
    "os.mkdir(str(data_folder + '/' + 'model'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the csv for building a model\n",
    "data = [['all_training', '1', str(data_folder + '/' + 'train'), stain, 'ch1', 'ch2']]\n",
    "build_model_csv = pd.DataFrame(data, columns = ['condition', 'set number', 'set location', 'note', 'ch1', 'ch2']) \n",
    "\n",
    "#saves csv to newly created model directory\n",
    "build_model_csv.to_csv(data_folder + '/' + 'model/' + 'images_to_build_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates the csv for applying a model\n",
    "apply_model_csv = pd.DataFrame(columns = ['condition', 'set number', 'set location', 'note', 'ch1'])\n",
    "\n",
    "set_number = 0\n",
    "for folders in test_paths:\n",
    "    str_set_number = str(set_number)\n",
    "    pattern = str(data_folder + '/' + '(.*?)' + '/threshold_applied_images/')\n",
    "    substring = re.search(pattern, folders).group(1)\n",
    "\n",
    "    df2 = pd.DataFrame({'condition': [substring], 'set number': [str_set_number], 'set location': [folders], 'note': [stain], 'ch1': ['ch1']})\n",
    "    apply_model_csv = apply_model_csv.append(df2)\n",
    "    \n",
    "    set_number += 1\n",
    "    \n",
    "apply_model_csv.to_csv(data_folder + '/' + 'model/' + 'images_to_apply_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step X: Print the inputs that should be added to VAMPIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Model CSV Path: /Users/hhelmbre/Desktop/6-17-2020-fiberfimages/iba1/model/images_to_build_model.csv\n",
      "Apply Model CSV Path: /Users/hhelmbre/Desktop/6-17-2020-fiberfimages/iba1/model/images_to_apply_model.csv\n",
      "Number of Shape Models (Recommended): 5\n",
      "Number of Shape Coordinates (Recommended): 50\n"
     ]
    }
   ],
   "source": [
    "print('Build Model CSV Path:', str(data_folder + '/' + 'model/' + 'images_to_build_model.csv'))\n",
    "print('Apply Model CSV Path:', str(data_folder + '/' + 'model/' + 'images_to_apply_model.csv'))\n",
    "print('Number of Shape Models (Recommended):', '5')\n",
    "print('Number of Shape Coordinates (Recommended):', '50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Open the VAMPIRE GUI, build, and then apply the model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## getboundary.py\n",
      "Check Label Status: Good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/getboundary.py:93: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  circularity = 4 * np.pi * area / perimeter ** 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: update your CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 124, in <lambda>\n",
      "    b2 = Button(rows[5], text='build model', width=12, command=(lambda e=ents: Model(e, True, progress_bar)))\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 83, in Model\n",
      "    getboundary(csv, progress_bar, entries)  # create registry csv and boundary stack\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/getboundary.py\", line 118, in getboundary\n",
      "    'Major Axis', 'Minor Axis', 'Circularity', 'Aspect Ratio']\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/pandas/core/generic.py\", line 5192, in __setattr__\n",
      "    return object.__setattr__(self, name, value)\n",
      "  File \"pandas/_libs/properties.pyx\", line 67, in pandas._libs.properties.AxisProperty.__set__\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/pandas/core/generic.py\", line 690, in _set_axis\n",
      "    self._data.set_axis(axis, labels)\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 183, in set_axis\n",
      "    \"values have {new} elements\".format(old=old_len, new=new_len)\n",
      "ValueError: Length mismatch: Expected axis has 0 elements, new values have 11 elements\n"
     ]
    }
   ],
   "source": [
    "import vampireanalysis\n",
    "from vampireanalysis import vampire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## getboundary.py\n",
      "error: update your CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 124, in <lambda>\n",
      "    b2 = Button(rows[5], text='build model', width=12, command=(lambda e=ents: Model(e, True, progress_bar)))\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 83, in Model\n",
      "    getboundary(csv, progress_bar, entries)  # create registry csv and boundary stack\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/getboundary.py\", line 72, in getboundary\n",
      "    if inputim is not 'labeled':\n",
      "UnboundLocalError: local variable 'inputim' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## getboundary.py\n",
      "error: update your CSV file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/tkinter/__init__.py\", line 1705, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 124, in <lambda>\n",
      "    b2 = Button(rows[5], text='build model', width=12, command=(lambda e=ents: Model(e, True, progress_bar)))\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/vampire.py\", line 83, in Model\n",
      "    getboundary(csv, progress_bar, entries)  # create registry csv and boundary stack\n",
      "  File \"/Users/hhelmbre/opt/anaconda3/envs/vampirenv/lib/python3.7/site-packages/vampireanalysis/getboundary.py\", line 72, in getboundary\n",
      "    if inputim is not 'labeled':\n",
      "UnboundLocalError: local variable 'inputim' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "vampire()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 8: New visualization of VAMPIRE data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This should probably be built into VAMPIRE and not just into this notebook - think about this for the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still needs to be visualization steps here because what is output by vampire just is not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
