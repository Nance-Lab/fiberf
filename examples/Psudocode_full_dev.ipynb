{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose: To build out the skeleton Pseudo Code for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For now__: Moving my notes from my one one one with Elizabeth and will build out more in the next few days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Input .csv from experimental team to describe data\n",
    "2. CSV pulls the proper images from NDP (or wherever best storage location is determined to be)\n",
    "2a. There needs to be some integration with NDP to break the image into chunks with the appropriate zoom and then provide the original slice with locations of test and training images printed out.\n",
    "2b. I think to do this we are going to have to register the image to some kind of atlas... or somethign to determine regions so that the code can grab pictures\n",
    "3. Images need to be split\n",
    "3a. Regionally\n",
    "3b. Test Groups\n",
    "3c. Into Small enough sizes for most efficient processing by package\n",
    "3d. Magifications\n",
    "4. Threshold and segment\n",
    "4a. Ifthresholds (for general object identification) [July]\n",
    "4b. + Skeletonization (for specific highly branched morphometric analysis) [Robin]\n",
    "5. Split data into testing and training groups\n",
    "6. Shape factor analysis on both models (before ML model)\n",
    "7. Feed 4(1) and 4(2) separately to modified VAMPIRE package to build models\n",
    "8. Store created models\n",
    "9. Test models with testing data sets\n",
    "10. Data output\n",
    "11. Comprehensive CSV for optional additional analysis\n",
    "12. Data Visualization\n",
    "13. Save all data into some storage location (Google Drive?)\n",
    "\n",
    "\n",
    "Other Notes: \n",
    "1. Modified VAMPIRE package: Worth forking the Wirtz lab repository now and building on by ourselves possibly – adding that fork to our repository - COMPLETE\n",
    "2. Want a repository that works through Binder? Preferably so the Neonatalogy lab can do this straight through a web interface\n",
    "3. Along with outputs want to output the variables used for all of the steps on days that experiments were run with an easy print out maybe for lab notebook storage? (A way to integrate the electronic lab notebook I want to get more fine tuned for our lab with a standard lab notebook - and provide some under the hood knowledge for Neonatology)\n",
    "\n",
    "4. Add in an optimization step for what size of image is sufficient for cropping down the whole scan images \n",
    "5. Including an analysis before creating that analysis that selects the best # of shape modes and #coordinate points – maybe we could reach out the Denis Wirtz lab about this or build in our own integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Goal:\n",
    "\n",
    "1. Get a bunch of images from a slice of the ferret brain\n",
    "2. Put them in a folder\n",
    "3. Perform thresholding within the Jupyter Notebook\n",
    "3. Integrate vampire into the Jupyter Notebook\n",
    "4. Run those images and get an output within the notebook or specific folder (which should will need a results output)\n",
    "5. Save all of this information to some results folder\n",
    "6. See if it works in binder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Goals:\n",
    "1. Build out ifthresholds more for immunohistochemistry stains\n",
    "2. Build in NDP regional registration and automatic image breakdown\n",
    "3. Integrate Google Drive\n",
    "4. New visualizations based on what came from paper\n",
    "5. Statistics possibly with Rthon\n",
    "6. Speed up any slow processes with Cython\n",
    "7. Integrate ifThresholds to pick and perform the best thresholding (or integrate a step to say whether this needs to be done or not)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 1: Import necessary packages*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import io\n",
    "from skimage import filters\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage import segmentation\n",
    "from skimage import color\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 2: User Inputs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data folder to the stain you are running morphology on (right now only works one stain at a time)\n",
    "#rerun for each individual stain\n",
    "\n",
    "#Folder breakdown: stain>animal>region>actual images\n",
    "data_folder = '/Users/hhelmbre/Desktop/6-17-2020-fiberfimages/iba1'\n",
    "\n",
    "#Image type of your images (they should all be the same type)\n",
    "image_file_type = '.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Google Drive Integration*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to this website: https://developers.google.com/drive/api/v3/quickstart/python?authuser=1\n",
    "2. Make sure the appropriate google account is open in the top right corner\n",
    "3. Click \"Enable the Drive API\" (blue button)\n",
    "4. Select 'Desktop App' from the drop down list\n",
    "5. Select Create\n",
    "6. Download the credentials\n",
    "7. Rename them client_secrets.json\n",
    "\n",
    "\n",
    "NOTE: client_secrets.json and credentials.json are files in the .gitignore for this respository. For online safety, do not change this or push either of these to Git to keep your google accounts secure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This runs the google integration - it will open another web browser. When allowed leave the authentication page open. \n",
    "#Sometimes there is an error when this page is closed.\n",
    "\n",
    "import pydrive\n",
    "from pydrive.auth import GoogleAuth as gauth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "from pydrive.auth import GoogleAuth\n",
    "\n",
    "#  Creates local webserver and auto handles authentication.\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth()\n",
    "\n",
    "#  Create GoogleDrive instance with authenticated GoogleAuth instance\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Threshold and segment everything and then split test and train*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_list = os.listdir(data_folder)\n",
    "folder_list = np.asarray(folder_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code for macs to get rid of an aesthetic file called '.DS_Store'\n",
    "k=0\n",
    "mac_annoyance= 'DS_Store'\n",
    "for folders in folder_list:\n",
    "    if mac_annoyance in str(folders):\n",
    "        folder_list = np.delete(folder_list, (k), axis=0)\n",
    "    else:\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Folder breadown should be (1) stains, (2) animals, (3) regions\n",
    "#this code gets a list of all the pat\n",
    "threshold_paths = []\n",
    "for animals in folder_list:\n",
    "    region_list = os.listdir(str(data_folder + '/' + animals))\n",
    "    region_list = np.asarray(region_list)\n",
    "    \n",
    "    k=0\n",
    "    for regions in region_list:\n",
    "        if mac_annoyance in str(regions):\n",
    "            region_list = np.delete(region_list, (k), axis=0)\n",
    "        else:\n",
    "            k+=1\n",
    "    \n",
    "    for regions in region_list:\n",
    "        path = str(data_folder + '/' + animals + '/' + regions)\n",
    "        threshold_paths.append(path)\n",
    "    \n",
    "                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step X: Test and Train Split before Thresholding*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go through each bottom folder within the input data folder\n",
    "#Split the images into test and train\n",
    "#Those for train move to the ov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 3: Threshold and Segment Images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3a: Import and threshold images from 'data_folder' from downloaded NDP images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = os.listdir(data_folder)\n",
    "image_list = np.asarray(image_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing anything that isn't an image from the image list*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=0\n",
    "for images in image_list:\n",
    "    if image_file_type in str(images):\n",
    "        k+=1\n",
    "    else:\n",
    "        image_list = np.delete(image_list, (k), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*back to what will be the main code*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*need to go in and add code to create a reasonable cut off for the min_size remove small objects*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Go in and add code that does a better job at separating overlapping cells (maybe this is just in thresholding*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a folder for the new tresholded images\n",
    "os.mkdir(str(data_folder + '/' + 'threshold_applied_images'))\n",
    "\n",
    "#initializing a pandas dataframe\n",
    "overall_region_meas = pd.DataFrame(columns = ['Filename', 'ImageID', 'ObjectID', 'X', 'Y', 'Area', 'Perimeter', 'Major Axis', 'Minor Axis', 'Circularity', 'Aspect Ratio'])\n",
    "\n",
    "#initializing a count\n",
    "k=1\n",
    "\n",
    "#Looping through all images in list (this task should be put to multiple CPUs in future if a large data set)\n",
    "for images in image_list:\n",
    "    \n",
    "    \n",
    "    #initializing a pandas data frame for measurement data\n",
    "    region_meas = pd.DataFrame()\n",
    "    \n",
    "    #Going through each of the images to get their binarized images and measurement info\n",
    "    name = str(data_folder + '/' + images)\n",
    "    im = io.imread(name)\n",
    "    im = im[:,:,2]\n",
    "    threshold = filters.threshold_otsu(im)\n",
    "    binary = morphology.closing(im < threshold, morphology.square(5))\n",
    "    label_image = measure.label(binary, return_num=False, connectivity=2)\n",
    "    binary2 = morphology.remove_small_objects(label_image, min_size=400, connectivity=2, in_place=True)\n",
    "    invert_binary2 = np.invert(binary2)\n",
    "    \n",
    "    # Saving the thresheld images to their own folder with modified names\n",
    "    im_to_save = Image.fromarray(np.uint8(binary2), mode='L')\n",
    "    new_name = str(data_folder + '/' + 'threshold_applied_images' + '/' + images)\n",
    "    new_name = new_name.replace('.jpg','_threshold.jpg')\n",
    "    im_to_save.save(new_name)\n",
    "    \n",
    "    \n",
    "    #Saving the region properties as a csv\n",
    "    props = measure.regionprops_table(binary2, properties= ('centroid', 'area', 'perimeter', 'major_axis_length', 'minor_axis_length'))\n",
    "    props_meas = pd.DataFrame(props)\n",
    "    region_meas['X'] = props_meas['centroid-0']\n",
    "    region_meas['Y'] = props_meas['centroid-1']\n",
    "    region_meas['Area'] = props_meas['area']\n",
    "    region_meas['Perimeter'] = props_meas['perimeter']\n",
    "    region_meas['Major Axis'] = props_meas['major_axis_length']\n",
    "    region_meas['Minor Axis'] = props_meas['minor_axis_length']\n",
    "    region_meas['Circularity'] = (region_meas['Area']*4*np.pi)/(region_meas['Perimeter']**2)\n",
    "    region_meas['Aspect Ratio'] = (region_meas['Major Axis']/region_meas['Minor Axis'])\n",
    "    region_meas.insert(0, 'Filename', images)\n",
    "    region_meas.insert(1, 'ImageID', k)\n",
    "    region_meas.insert(2, 'ObjectID', np.arange(len(region_meas)))\n",
    "\n",
    "    overall_region_meas = overall_region_meas.append(region_meas)\n",
    "    k+=1\n",
    "\n",
    "path = '/Users/hhelmbre/Desktop/fiberf_data/threshold_applied_images/'\n",
    "overall_region_meas.to_csv(path+'c1_registry.csv', index=False)\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Vampire Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 5: Train and Test Split Images*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The following will pull up the GUI as a popup - I want to be able to input values into the GUI straight from here not have to point and click*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#We are going to work with what we have an have a print out here of what to input in the VAMPIRE GUI - it is still faster than it used to be. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Build and then apply model with the vampire GUI (will work on making it not GUI later)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step X: Print the inputs that should be added to VAMPIRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vampireanalysis\n",
    "from vampireanalysis import vampire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vampire()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Step 8: New visualization of VAMPIRE data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This should probably be built into VAMPIRE and not just into this notebook - think about this for the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There still needs to be visualization steps here because what is output by vampire just is not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
